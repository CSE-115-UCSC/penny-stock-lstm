{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30f134-0578-41ff-b992-337a12cc4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennystockpipeline.PennyStockData import PennyStockData\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime, timedelta\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "## Initializing\n",
    "DATABASE_NAME_WITH_PATH = \"mod_historicaldata.db\"\n",
    "TABLE_NAME = \"all_historical_modified\"\n",
    "\n",
    "#psd = PennyStockData(database_name_with_path, table_name, impute=True, verbose=2).get_columns(columns).normalize(['close', 'volume_weighted_average']).create_sequences(sequence_length, prediction_length)\n",
    "psd = PennyStockData(DATABASE_NAME_WITH_PATH, TABLE_NAME, impute=True, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc0378-6a44-48bd-af97-4bdac41b9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['ticker_id', 'p_date', 'close', 'volume_weighted_average']\n",
    "COLUMNS = ['ticker_id', 'p_date', 'p_time', 'volume_weighted_average']\n",
    "COLUMNS_TO_NORMALIZE = ['volume_weighted_average']\n",
    "\n",
    "SEQUENCE_LENGTH = 20\n",
    "PREDICTION_LENGTH = 20\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "psd = psd.get_columns(COLUMNS).normalize(COLUMNS_TO_NORMALIZE).create_sequences(SEQUENCE_LENGTH, PREDICTION_LENGTH).split_dataset(split=TRAIN_TEST_SPLIT, to_torch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b24dc-8ed5-4e9f-8a2a-aaec074bbc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c432d-7b30-409a-8023-ad6a1e1c829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for implementing Deep Neural Network \n",
    "from pennystockpipeline.PennyStockModel import PennyStockModel\n",
    "\n",
    "# Prepare model parameters\n",
    "INPUT_SIZE = len(COLUMNS_TO_NORMALIZE)\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_SIZE = 64\n",
    "OUTPUT_SIZE = len(COLUMNS_TO_NORMALIZE)\n",
    "DROPOUT = 0\n",
    "# Define the model, loss function, and optimizer\n",
    "model = PennyStockModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE, DROPOUT, device='cuda')\n",
    "model = model.to(model.device)\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46efaf0-4355-43ad-9e6b-36232dd927d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## single ticker, ticker_id = 9\n",
    "##\n",
    "\n",
    "#torch.random_seed(0), \n",
    "#batch = 32\t\t\t\t\t\t\t\tbatch = 16\n",
    "#model\tepoch=40\t\t\t\t\t\tmodel\tepoch=40\n",
    "#best_loss: 0.0020826306399612804\t\tbest_loss: 0.004081749377291999\n",
    "#diff\t0.0005\t\t\t\t\t\t\tdiff\t0.0003\n",
    "\n",
    "#torch.random_seed(0), \n",
    "#batch = 32\t\t\t\t\t\t\t\tbatch = 16\n",
    "#model\tepoch=50\t\t\t\t\t\tmodel\tepoch=50\n",
    "#best_loss: 0.002037114063568879\t\tbest_loss: 0.004062295620315126\n",
    "#diff\t-0.0003\t\t\t\t\t\t\tdiff\t0.0034\n",
    "\n",
    "##\n",
    "## multiple ticker, ticker_id <> 30\n",
    "##\n",
    "\n",
    "#torch.random_seed(0), \n",
    "#batch = 32\t\t\t\t\t\t\t\tbatch = 16\n",
    "#model\tepoch=40\t\t\t\t\t\tmodel\tepoch=40\n",
    "#best_loss: 0.060114274077022856\t\tbest_loss: 0.11994675780084663\n",
    "#diff\t0.0008\t\t\t\t\t\t\tdiff\t-0.0021\n",
    "\n",
    "#torch.random_seed(0), \n",
    "#batch = 32\t\t\t\t\t\t\t\tbatch = 16\n",
    "#model\tepoch=50\t\t\t\t\t\tmodel\tepoch=50\n",
    "#best_loss: 0.060114274077022856\t\tbest_loss: 0.11994675780084663 \n",
    "#diff\t-0.005\t\t\t\t\t\t\tdiff\t-0.0032\n",
    " \n",
    "## can we use transfer learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f87c3d-45c6-4674-a6e1-66767280ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32   # batch 16, run epoch 40; batch 32, run epoch 40 or 50 with torch.random_seed(0)\n",
    "model = model.create_dataloaders(psd, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460b3f4-f9ae-4207-9975-62f45b1f3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 40\n",
    "# Train the model\n",
    "#model = model.load_model()\n",
    "\n",
    "model = model.train_model(loss_fn, optimizer, num_epochs = NUM_EPOCHS).plot_training_test_loss()#.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483781f-6958-4d4b-ae25-781d8fd2d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST_STEPS = 20\n",
    "model = model.forecast(num_forecast_steps = FORECAST_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc61063-5364-43fd-bc70-c1308fef7bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model.load_model()\n",
    "model = model.plot_forecasting()#, i_sequence_to_plot, i_forecasted_values, i_combined_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe56bf-f1c3-4068-92cd-9adbf840c84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf5387-42ad-4835-b8c4-01bb1d64864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582eb800-b0a6-4304-af25-76e34b0428b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Library for implementing Deep Neural Network \n",
    "psd2 = psd\n",
    "\n",
    "from pennystockpipeline.PennyStockModel2 import PennyStockModel2\n",
    "\n",
    "# Prepare model parameters\n",
    "INPUT_SIZE = len(COLUMNS_TO_NORMALIZE)\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_SIZE = 32\n",
    "OUTPUT_SIZE = len(COLUMNS_TO_NORMALIZE)\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Define the model, loss function, and optimizer\n",
    "model2 = PennyStockModel2(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE, DROPOUT, device='cuda')\n",
    "model2 = model2.to(model2.device)\n",
    "loss_fn2 = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
    "print(model2)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "model2 = model2.create_dataloaders(psd2, BATCH_SIZE)\n",
    "NUM_EPOCHS = 100\n",
    "# Train the model\n",
    "#model2 = model2.load_model()\n",
    "model2 = model2.train_model(loss_fn2, optimizer2, num_epochs = NUM_EPOCHS).plot_training_test_loss()#.save_model()\n",
    "\n",
    "model2 = model2.forecast(num_forecast_steps = FORECAST_STEPS)\n",
    "model2 = model2.plot_forecasting()#, i_sequence_to_plot, i_forecasted_values, i_combined_index)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
