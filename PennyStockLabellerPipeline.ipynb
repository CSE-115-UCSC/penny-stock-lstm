{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d30f134-0578-41ff-b992-337a12cc4ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'ACHR', '2022-07-12', '16:30', 3.0307, 3.0301, 3.03, 3.0301, 3.03, 1657643400, 269, 4]\n",
      "[DEBUG][PennyStockData]: Imputed len(data): 965607\n",
      "[1, 'ACHR', '2022-07-12', '16:30', 3.0307, 3.0301, 3.03, 3.0301, 3.03, 1657643400, 269, 4, 0]\n",
      "next_max_date: 2024-06-01\n"
     ]
    }
   ],
   "source": [
    "from pennystockpipeline.PennyStockData import PennyStockData\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime, timedelta\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "## Initializing\n",
    "DATABASE_NAME_WITH_PATH = \"mod_historicaldata.db\"\n",
    "TABLE_NAME = \"all_historical_modified\"\n",
    "\n",
    "#psd = PennyStockData(database_name_with_path, table_name, impute=True, verbose=2).get_columns(columns).normalize(['close', 'volume_weighted_average']).create_sequences(sequence_length, prediction_length)\n",
    "psd = PennyStockData(DATABASE_NAME_WITH_PATH, TABLE_NAME, impute=True, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addc0378-6a44-48bd-af97-4bdac41b9b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][PennyStockData]: Performing ticker-wise normalization on ['volume_weighted_average']\n",
      "[1, '2022-07-12', '16:30', 3.0307]\n",
      "[INFO][PennyStockData]: Performing global normalization on ['volume_weighted_average'] using MixMaxScaler\n",
      "[0.3889893316214954]\n"
     ]
    }
   ],
   "source": [
    "#columns = ['ticker_id', 'p_date', 'close', 'volume_weighted_average']\n",
    "COLUMNS = ['ticker_id', 'p_date', 'p_time', 'volume_weighted_average']\n",
    "COLUMNS_TO_NORMALIZE = ['volume_weighted_average']\n",
    "\n",
    "SEQUENCE_LENGTH = 20\n",
    "PREDICTION_LENGTH = 20\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "psd = psd.get_columns(COLUMNS).normalize(COLUMNS_TO_NORMALIZE)#.create_sequences(SEQUENCE_LENGTH, PREDICTION_LENGTH).split_dataset(split=TRAIN_TEST_SPLIT, to_torch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1b24dc-8ed5-4e9f-8a2a-aaec074bbc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for implementing Deep Neural Network \n",
    "from pennystockpipeline.PennyStockLabeller import PennyStockLabeller\n",
    "HORIZON = 1.01\n",
    "COLUMNS_TO_COMPARE = [\"volume_weighted_average\"]\n",
    "\n",
    "labeller = PennyStockLabeller(psd, 2)\n",
    "#labeller = labeller.labelize(column_to_compare = COLUMN_TO_COMPARE, horizon = HORIZON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b64ba-414f-4ed0-8ff1-e0fec69d4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(np.transpose(psd.data)[0]))\n",
    "\n",
    "df = pd.DataFrame(psd.data, columns=psd.headers)\n",
    "#df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))\n",
    "df.groupby('ticker_id').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c432d-7b30-409a-8023-ad6a1e1c829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def labelize(labeller, columns_to_compare=[\"volume_weighted_average\"], horizon = 0.1):\n",
    "    unlabelled_data_raw = np.array(psd.data)\n",
    "    number_of_records = len(unlabelled_data_raw)\n",
    "    \n",
    "    unlabelled_data_df = pd.DataFrame(unlabelled_data_raw, columns=psd.headers)\n",
    "    \n",
    "    columns_to_compare_str = [column_to_compare + \"_h_str\" for column_to_compare in columns_to_compare]\n",
    "    labels_df_data = [\"no_buy\"] * number_of_records\n",
    "    labels_df = pd.DataFrame(data = labels_df_data, columns = columns_to_compare_str)\n",
    "\n",
    "    labels_cursor = 0\n",
    "\n",
    "    for ticker_id in unlabelled_data_df['ticker_id'].unique():\n",
    "        ticker_data_df = unlabelled_data_df[unlabelled_data_df['ticker_id'] == ticker_id].copy()\n",
    "        print(f'Ticker: {ticker_id}')\n",
    "        \n",
    "        for ticker_date in ticker_data_df['p_date'].unique():\n",
    "            ticker_date_data_df = ticker_data_df[ticker_data_df['p_date'] == ticker_date].copy()\n",
    "\n",
    "            print(f'---> Date: {ticker_date}')\n",
    "            #ticker_date_data_df.reset_index(drop=True, inplace=True)\n",
    "            #ticker_date_data_df.reindex()\n",
    "\n",
    "            buy_triggered = False\n",
    "            #print(f'label start: {labels_cursor}')\n",
    "            #labels_cursor = labels_cursor + len(ticker_date_data_df)\n",
    "            #print(f'label end: {labels_cursor}')\n",
    "\n",
    "            labels_df_cursor = 0\n",
    "\n",
    "            for ctc in columns_to_compare:\n",
    "                if ctc in ticker_date_data_df.columns:\n",
    "                    for m in ticker_date_data_df.index:\n",
    "                        print(f'---> ticker_date_data_df.index.min() and max(): {ticker_date_data_df.index.min()}, {ticker_date_data_df.index.max()}')\n",
    "                        if m >= ticker_date_data_df.index.max():\n",
    "                            break\n",
    "\n",
    "                        #print(f'{(np.float32(ticker_date_data_df[ctc][m+1:]) / np.float32(ticker_date_data_df[ctc][m]))}')\n",
    "                        #print(f'{horizon < (np.float32(ticker_date_data_df[ctc][m+1:]) / np.float32(ticker_date_data_df[ctc][m]))}')\n",
    "                        #x = lambda a : a + 10\n",
    "                        comparison_lambda = lambda h, x, d: np.insert((h < (np.float32(x) / np.float32(d))), 0, False)\n",
    "                        comparison_truth_table = comparison_lambda(horizon, ticker_date_data_df.loc[m+1:, ctc], ticker_date_data_df.loc[m, ctc])\n",
    "                        #comparison_truth_table = (np.insert((horizon < (np.float32(ticker_date_data_df[ctc][m+1:]) / np.float32(ticker_date_data_df[ctc][m]))), 0, False))\n",
    "                        print(f'--------> {m} comparison_truth_table: {comparison_truth_table}')\n",
    "                        \n",
    "                        #print([\"buy\" if h else \"no_buy\" for h in (np.insert((horizon < (np.float32(ticker_date_data_df[ctc][m+1:]) / np.float32(ticker_date_data_df[ctc][m]))), 0, False)).reshape(-1,1).squeeze()])\n",
    "                        #another_array = np.array([\"buy\" if h else \"no_buy\" for h in (np.insert(horizon < (np.float32(ticker_date_data_df[ctc][m+1:]) / np.float32(ticker_date_data_df[ctc][m])), 0, False))])\n",
    "                        #print(f'--------> {another_array.shape} another_array: {another_array}')\n",
    "                        \n",
    "                        #if True in comparison_truth_table:\n",
    "                        ### Now update the df _h_str and break for this day\n",
    "                        # Getting only true items\n",
    "                        labels_df_indices = ticker_date_data_df[:len(comparison_truth_table)].index[comparison_truth_table]\n",
    "                        #print(f'labels_df_indices: {labels_df_indices}')\n",
    "                        #labels_df[ctc+\"_h_str\"][labels_df_indices] = \"buy\"\n",
    "                        labels_df.loc[labels_df_indices, ctc+\"_h_str\"] = \"buy\"\n",
    "                        print(labels_df[ctc+\"_h_str\"][ticker_date_data_df.index])\n",
    "                        #labels_df.loc[ticker_date_data_df.index[m]:-1, ctc+\"_h_str\"] = [\"buy\" if h else \"no_buy\" for h in (np.insert(horizon < (np.float32(ticker_date_data_df[ctc][m+1:]) / np.float32(ticker_date_data_df[ctc][m])), 0, False))].reshape(-1,1).squeeze()\n",
    "                        if (labels_df_indices.shape[0] > 0):\n",
    "                            buy_triggered = True\n",
    "                            ticker_date_data_df = None\n",
    "                            break\n",
    "                            \n",
    "                        \n",
    "                    if buy_triggered:\n",
    "                        ticker_date_data_df = None\n",
    "                        break\n",
    "        ticker_date_data_df = None\n",
    "        \n",
    "    labelled_data_df = pd.concat([unlabelled_data_df, labels_df], axis=1)        \n",
    "    labeller.labelled_data_df = labelled_data_df\n",
    "\n",
    "    return labeller\n",
    "\n",
    "HORIZON = 1.001\n",
    "lbller = labelize(labeller, columns_to_compare = COLUMNS_TO_COMPARE, horizon = HORIZON)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4162d286-6952-4369-9578-56ba47ea518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeller = labeller.labelize(columns_to_compare = COLUMNS_TO_COMPARE, horizon = HORIZON)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29756caa-4b10-4b61-9189-961f6c6030df",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeller.to_csv('labelled_psd_data.csv')\n",
    "#lbller.labelled_data_df.to_csv('labelled_psd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d1ed07-21b5-48b9-b072-7d07a66228a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27887dee-52ce-4f75-a957-b0b39429c3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9c89e-70c1-4e40-beb1-be6e4cc6758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_by_ticker = {}\n",
    "    for ticker in unlabelled_data_df['ticker_id'].unique():\n",
    "        data_by_ticker[ticker] = unlabelled_data_df[unlabelled_data_df['ticker_id'] == ticker].copy()\n",
    "        # now, we loop through each date and time to find if vwa > ticker's_first_vwa * gain_threshold * 100  first value\n",
    "        for ticker_date in data_by_ticker[ticker]['p_date'].unique():\n",
    "            data_by_ticker_date = np.indices(data_by_ticker[ticker]['p_date'] == ticker_date)\n",
    "            \n",
    "            data_by_ticker_date = pd.DataFrame([data_by_ticker[ticker]['p_date'] == ticker_date], columns=data_by_ticker.keys())\n",
    "            print(data_by_ticker_date)\n",
    "            \n",
    "            print(data_by_ticker[ticker]['p_date'] == ticker_date)\n",
    "            print(f'ticker: {ticker} date: {ticker_date}')\n",
    "\n",
    "            #print(data_by_ticker[data_by_ticker[ticker]['p_date'] == ticker_date])\n",
    "\n",
    "            \n",
    "            #data_by_ticker_date[ticker_date] = data_by_ticker[ticker][data_by_ticker[ticker]['p_date'] == ticker_date].copy()\n",
    "            for ctn in column_to_compare:\n",
    "                new_column = []\n",
    "                if ctn in unlabelled_data_df.columns:\n",
    "                    #print(len(data_by_ticker[data_by_ticker[ticker]['p_date']==ticker_date]))\n",
    "                    #data_by_ticker_date[ticker_date][ctn+\"_h_str\"] = 'no_buy'\n",
    "                    #(data_by_ticker[ticker]['p_date'] == ticker_date).ctn\n",
    "                    #h_values = data_by_ticker[data_by_ticker[ticker][ticker_date]][ctn] / data_by_ticker[data_by_ticker[ticker][ticker_date]][ctn][0]\n",
    "                    h_values = (data_by_ticker[ticker]['p_date'] == ticker_date)[ctn] / (data_by_ticker[ticker]['p_date'] == ticker_date)[ctn][0]\n",
    "                    new_column[ctn+\"_h_str\"] = [\"buy\" if np.greater_equal(h_values, horizon) else 'no_buy']\n",
    "                    ## new_column[ctn+\"_h_str\"] = [\"buy\" if np.any(h_values, where=np.greater_equal(horizon)) else 'no_buy']\n",
    "                    data_by_ticker[ticker] = pd.concat(data_by_ticker[ticker], new_column[ctn+\"_h_str\"])\n",
    "                    ##data_by_ticker[ticker][data_by_ticker[ticker]['p_date'] == ticker_date]\n",
    "\n",
    "            \n",
    "            #data_by_ticker_date[ticker_date] = pd.DataFrame()\n",
    "            #data_by_ticker_date[ticker_date] = data_by_ticker[ticker][data_by_ticker[ticker]['p_date'] == ticker_date].copy()\n",
    "            # each record is divided by the first record, i.e. vwa at day start\n",
    "            #for ctn in column_to_compare:\n",
    "            #    if ctn in unlabelled_data_df.columns:\n",
    "            #        # we initialize the h_values with 'no buy'\n",
    "            #        data_by_ticker_date[ticker_date][ctn+\"_h_str\"] = 'no_buy'\n",
    "            #        h_values = data_by_ticker_date[ticker_date][ctn] / data_by_ticker_date[ticker_date][ctn][0]\n",
    "            #        #data_by_ticker[ticker][ctn+\"_h_str\"] = [\"buy\" if h >= horizon for h in h_values]\n",
    "            #        data_by_ticker_date[ticker_date][ctn+\"_h_str\"] = [\"buy\" if np.any(h_values, where=np.greater_equal(horizon)) else 'no_buy']\n",
    "\n",
    "        #for ticker_date in data_by_ticker[ticker]:\n",
    "            # create a temporary DataFrame to hold the current data\n",
    "        temp_df = pd.DataFrame(data_by_ticker[ticker].values, columns=data_by_ticker[ticker].keys())\n",
    "        labelled_data = pd.concat([labelled_data, temp_df], axis=0, ignore_index=True)\n",
    "        \n",
    "    #for ticker in data_by_ticker:\n",
    "    #    # create a temporary DataFrame to hold the current data\n",
    "    #    temp_df = pd.DataFrame(labelled_data.values, columns=labelled_data.keys())\n",
    "    #    labelled_data = pd.concat([labelled_data, temp_df], axis=0, ignore_index=True)\n",
    "\n",
    "    # optionally, you can reset the index if needed\n",
    "    labelled_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #labelled_data[column_to_compare] = labeller.scaler.fit_transform(labelled_data[column_to_compare])\n",
    "    \n",
    "    #normalized_data = normalized_data.drop(columns=['ticker_id'])\n",
    "    #normalized_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f'Length of labelled_data: {len(labelled_data)}')\n",
    "    print(f'labelled_data:')\n",
    "    print(f'{labelled_data}')\n",
    "\n",
    "    labeller.labelled_data = labelled_data.values.tolist()\n",
    "    labeller.labelled_headers = labelled_data.columns.tolist()\n",
    "    \n",
    "    labeller.label_data = labelled_data[\"g_value\"].values.tolist()\n",
    "    labeller.label_header = \"g_value\"\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3ae7a-be1b-4012-9cc4-602a7bc6038a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
